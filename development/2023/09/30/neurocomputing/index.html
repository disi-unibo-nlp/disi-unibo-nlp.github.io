<!doctype html>




<html
    dir="ltr"
    lang="en"
    class=" "
>
    <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#ffffff">
    <link rel="stylesheet" href="/assets/css/app.css">
    <link
        rel="shortcut icon"
        type="image/png"
        
            href="/assets/img/logo.jpg"
        
    >
    <script defer src="https://unpkg.com/alpinejs@3.9.0/dist/cdn.min.js"></script>
    <script
        src="https://cdn.jsdelivr.net/npm/js-cookie@3.0.5/dist/js.cookie.min.js"
    ></script>
    <link
        rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css"
        integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg=="
        crossorigin="anonymous"
        referrerpolicy="no-referrer"
    >
    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma-social@1/bin/bulma-social.min.css">
    
    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Elsevier - Neurocomputing | UniboNLP</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="Elsevier - Neurocomputing" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="We are excited to announce that our group has two papers accepted at Neurocomputing" />
<meta property="og:description" content="We are excited to announce that our group has two papers accepted at Neurocomputing" />
<link rel="canonical" href="https://www.csrhymes.com/development/2018/05/28/why-use-a-static-site-generator.html" />
<meta property="og:url" content="https://www.csrhymes.com/development/2018/05/28/why-use-a-static-site-generator.html" />
<meta property="og:site_name" content="UniboNLP" />
<meta property="og:image" content="https://neurocomputinglab.com/wp-content/uploads/2020/03/neurocomp-1.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-09-30T00:00:00+00:00" />
<script type="application/ld+json">
{"description":"We are excited to announce that our group has two papers accepted at Neurocomputing","headline":"Elsevier - Neurocomputing","dateModified":"2023-09-30T00:00:00+00:00","datePublished":"2023-09-30T00:00:00+00:00","url":"https://www.csrhymes.com/development/2018/05/28/why-use-a-static-site-generator.html","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.csrhymes.com/development/2018/05/28/why-use-a-static-site-generator.html"},"image":"https://neurocomputinglab.com/wp-content/uploads/2020/03/neurocomp-1.jpg","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <!-- head scripts -->
</head>

    <body>

        


        
        <nav
    class="navbar is-primary "
    x-data="{ openNav: false }"
>
    <div class="container navigation">
        <div class="navbar-brand">
            <a href="/" class="navbar-item ">
                <img src="/assets/css/logo.svg" alt="Logo" class="navbar-logo">
            </a>
            <a
                role="button"
                class="navbar-burger burger"
                aria-label="menu"
                aria-expanded="false"
                data-target="navMenu"
                :class="{ 'is-active': openNav }"
                x-on:click="openNav = !openNav"
            >
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu" id="navMenu" :class="{ 'is-active': openNav }">
            <div class="navbar-start">
                
                    
                        
                            <a
                                href="/people/"
                                class="navbar-item "
                            >People</a>
                        
                    
                        
                            <a
                                href="/publications/"
                                class="navbar-item "
                            >Publications</a>
                        
                    
                        
                            <a
                                href="/applications/"
                                class="navbar-item "
                            >Applications</a>
                        
                    
                        
                            <a
                                href="/projects/"
                                class="navbar-item "
                            >Projects</a>
                        
                    
                        
                            <a
                                href="/datasets/"
                                class="navbar-item "
                            >Datasets</a>
                        
                    
                        
                            <a
                                href="/theses/"
                                class="navbar-item "
                            >Theses</a>
                        
                    
                        
                            <a
                                href="/deadlines/"
                                class="navbar-item "
                            >Deadlines</a>
                        
                    
                
            </div>

            <div class="navbar-end">
                
            </div>
        </div>
    </div>
</nav>
        
            <section
    class="prime hero  is-medium  is-bold is-primary"
    
>
    <div class="hero-body ">
        <div class="container">
            <h1 class="title is-2">Elsevier - Neurocomputing</h1>
            <p class="subtitle is-3"></p>
            
        </div>
    </div>
</section>
        
        

        <section class="section">
            <div class="container">
                <div class="columns is-multiline">
                    
                    <div class="column is-12">
                        

                        

                        

                        

                        <div class="content">
    
        <p>Published: Sep 30, 2023</p>
    
    
    
    <p>UniboNLP has <b>3 long papers published in Neurocomputing 2023.</b> Read to learn more on <b>dialog and long text summarization in data-scarcity scenarios</b> and <b>multimodal retrieval for fashion products</b>.</p>

<hr />

<h4>Align-Then-Abstract Representation Learning for Low-Resource Summarization</h4>
<p style="color:gray; margin-top:-10px;">by G. Moro and L. Ragazzi</p>

<p>
Generative transformer-based models have achieved state-of-the-art performance in text summarization. Nevertheless, they still struggle in real-world scenarios with long documents when trained in low-resource settings of a few dozen labeled training instances, namely in low-resource summarization (LRS). This paper bridges the gap by addressing two key research challenges when summarizing long documents, i.e., long-input processing and document representation, in one coherent model trained for LRS. Specifically, our novel align-then-abstract representation learning model (Athena) jointly trains a segmenter and a summarizer by maximizing the alignment between the chunk-target pairs in output from the text segmentation. Extensive experiments reveal that Athena outperforms the current state-of-the-art approaches in LRS on multiple long document summarization datasets from different domains.
</p>
<p></p>
<ul>
  <li>
    <a target="_blank" class="link" href="https://www.sciencedirect.com/science/article/pii/S0925231223004794">Check out the paper!</a>
  </li>
</ul>

<hr />

<h4>Efficient Text-Image Semantic Search: a Multi-modal Vision-Language Approach for Fashion Retrieval</h4>
<p style="color:gray; margin-top:-10px;">by G. Moro, S. Salvatori, and G. Frisoni</p>

<p>
In this paper, we address the problem of multi-modal retrieval of fashion products. State-of-the-art (SOTA) works proposed in literature use vision-and-language transformers to assign similarity scores to joint text-image pairs, then used for sorting the results during a retrieval phase. However, this approach is inefficient since it requires coupling a query with every record in the dataset and computing a forward pass for each sample at runtime, precluding scalability to large-scale datasets. We thus propose a solution that overcomes the above limitation by combining transformers and deep metric learning to create a latent space where texts and images are separately embedded, and their spatial proximity translates into semantic similarity. Our architecture does not use convolutional neural networks to process images, allowing us to test different levels of image-processing details and metric learning losses. We vastly improve retrieval accuracy results on the FashionGen benchmark (+18.71% and +9.22% Rank@1 on Image-to-Text and Text-to-Image, respectively) while being up to 512x faster. Finally, we analyze the speed-up obtainable by different approximate nearest neighbor retrieval strategies—an optimization precluded to current SOTA contributions. We release our solution as a web application available at https://disi-unibo-nlp.github.io/projects/fashion_retrieval/.
</p>
<p></p>
<ul>
  <li>
    <a target="_blank" class="link" href="https://www.sciencedirect.com/science/article/pii/S092523122300303X">Check out the paper!</a>
  </li>
</ul>

<hr />

<h4>Evidence, my Dear Watson: Abstractive Dialogue Summarization on Learnable Relevant Utterances</h4>
<p style="color:gray; margin-top:-10px;">by P. Italiani, G. Frisoni, G. Moro, A. Carbonaro, and C. Sartori</p>

<p>
Abstractive dialogue summarization requires distilling and rephrasing key information from noisy multi-speaker documents. Combining pre-trained language models with input augmentation techniques has recently led to significant research progress. However, existing solutions still struggle to select relevant chat segments, primarily relying on open-domain and unsupervised annotators not tailored to the actual needs of the summarization task. In this paper, we propose DearWatson, a task-aware utterance-level annotation framework for improving the effectiveness and interpretability of pre-trained dialogue summarization models. Precisely, we learn relevant utterances in the source document and mark them with special tags, that then act as supporting evidence for the generated summary. Quantitative experiments are conducted on two datasets made up of real-life messenger conversations. The results show that DearWatson allows model attention to focus on salient tokens, achieving new state-of-the-art results in three evaluation metrics, including semantic and factuality measures. Human evaluation proves the superiority of our solution in semantic consistency and recall. Finally, extensive ablation studies confirm each module’s importance, also exploring different annotation strategies and parameter-efficient fine-tuning of large generative language models.
</p>
<p></p>
<ul>
  <li>
    <a target="_blank" class="link" href="https://www.sciencedirect.com/science/article/pii/S0925231223012559">Check out the paper!</a>
  </li>
</ul>

</div>

<div class="tags">
    
</div>

                    </div>
                    
                </div>
            </div>
        </section>
        
            <footer class="footer">
    <div class="container">
        
        

        <!-- <div class="content is-small has-text-centered">
            <p class="">Email contact: gianluca.moro[at]unibo.it</p>
        </div> -->
    </div>
</footer>

        
        <script src="/assets/js/app.js" type="text/javascript"></script><!-- footer scripts -->
<script src="/assets/js/custom.js"></script>
    </body>
</html>
